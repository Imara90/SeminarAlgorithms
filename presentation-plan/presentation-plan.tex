\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}
\urldef{\mailsa}\path|{i.c.t.m.speek, a.c.stolwijk}@student.tudelft.nl|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip%
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter% start of an individual contribution

% first the title is needed
\title{Presentation Plan\\
FF-Replan: \& RFF\@: Exploiting classical AI planning for uncertain and probabilistic domains}

% a short form should be given in case it is too long for the running head
\titlerunning{Lecture Notes in Computer Science: Authors' Instructions}

\author{I.C.T.M Speek, A.C. Stolwijk}

%
\authorrunning{Presentation Plan Seminar Algorithms FF-replan \& RFF}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{Seminar Algorithms, Embedded Software,
Msc Embedded Systems,\\
Delft University of Technology\\
\mailsa\\
}

\toctitle{Lecture Notes in Computer Science}
\tocauthor{Authors' Instructions}
\maketitle

\section{Summary of given papers}

\subsection{FF-Replan: A Baseline for Probabilistic Planning}

At the first international probabilistic planning competition IPPC-04, most entries were Markov Decision Processes. The winner, FF-Replan, however was based on deterministic planning techniques.

FF-Replan is an action selection algorithm for online planning in probabilistic domains. Given a domain description, a goal and an initial state as a probabilistic planning problem, FF-Replan generates a deterministic planning problem. It determinizes the input domain at the start of the planning into a deterministic different domain. They consider two methods of determinization:
\begin{enumerate}
	\item \emph{Single-outcome determinization}: selects one outcome for each probabilistic construct using a variety of heuristics. The performance strongly depends on the methods for choosing the outcomes.
	\item \emph{All-outcomes determinization}: considers every probabilistic outcome as a dinstinct deterministic action. For each possible outcome  FF-Replan generates one seperate action for each effect. For nested probabilities, the all-outcomes procedure is applied recursively. This implies that FF-Replan will ceise selection actions whenever it enters a dead state. However when given no information, all probabilistic effects will be considered as equal which is a potential weakness. 
\end{enumerate}

After determinization FF-Replan then uses the deterministic FF planner to compute an ordered plan for the generated deterministic problem. This process is repeated when countering an unexpected state untill a goal state is reached. It maintains a partial state-action mapping using a hash-table which is initially empty. Whenever FF-Replan encounters a state which is not in the table, it determinizes the problem and synthesizes a plan using FF. It then simulates the plan according to the deterministic action definitions resulting in a state-action sequence whose pairs are put in the hash table . The first action of the plan in then executed in the environment, returning a new state. This partial policy is this produces in an online fashion. It would be valuable to look into incremental planning approaches that don't create a deterministic plan from scratch whenever an unexpected state is encountered or reusing previous planning effort. 

FF-Replan has some obvious shortcomings as it first determinizes the input domain, removing all probabilistic information from the problem and then synthesizes a plan. If an unexpected state should occur whilst executing, the planner replans in the same determinization. It also does not consider multiple potential effects if an action. 

By relying on search, FF-Replan could function with enormous speed and efficiency. However when dealing with difficult probabilistic problems attempting to span the spectrum of complexity ranging from deterministic problems to highly stochastic problems, FF-Replan is expected to come short. Because FF-Replan is developed hoping to inspire extensions and insight into the approach and planning domains, the authors can only hope to achieve this.

\subsection{Incremental Plan Aggregation for Generating Policies in MDPs}

Markov Decision Processes (MDPs) is the best known formalism for planning under
uncertainty. It can however be computationally intensive if large parts of the
policies are tried to optimize at once. Most recent MDP planning techniques are
using the following steps as a basis approach:

\begin{enumerate}
	\item Take MDP problem
	\item ``Determinize''  it into a classical planning problem
	\item Generate sequence of actions that represent a possible execution
		path
	\item MDP planner executes plan:
		\begin{itemize}
			\item If goal is reached, reports success
			\item Otherwise algorithm generates a new plan from failed state of the world
		\end{itemize}
\end{enumerate}

There are some issues with this approach:

\begin{itemize}
	\item It stops after the first computed path to a goal which is likely to fail
	\item May result in generating the same path over and over again
	\item Only generates an execution path, not a policy
\end{itemize}

The authors identified four aspects of policy generation for MDP planning
problems using a classical planning algorithm:

\begin{enumerate}
	\item How to determinize the MDP planning problem
	\item which plan (initial state, goal) to ask for
	\item How to incrementally aggregate the plans by the classical planner
		into a solution policy
	\item How to combine this coherently
\end{enumerate}

\section{Questions that arose}

\section{Criticism on the contribution of the paper}

\section{Relevant literature on the subject}

\section{Presentation setup}

\end{document}
